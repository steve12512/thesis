{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference, demographic_parity_ratio \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing \n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_17220\\1535556638.py:2: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith('2'):\n",
    "    tf.compat.v1.disable_eager_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('car_insurance_claim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>TIF</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>CLAIM_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.030200e+04</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>10295.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>9754.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "      <td>9663.000000</td>\n",
       "      <td>10302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.956631e+08</td>\n",
       "      <td>0.169288</td>\n",
       "      <td>44.837397</td>\n",
       "      <td>0.720443</td>\n",
       "      <td>10.474062</td>\n",
       "      <td>33.416424</td>\n",
       "      <td>5.329159</td>\n",
       "      <td>0.800718</td>\n",
       "      <td>1.710153</td>\n",
       "      <td>8.298148</td>\n",
       "      <td>0.266550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.864675e+08</td>\n",
       "      <td>0.506512</td>\n",
       "      <td>8.606445</td>\n",
       "      <td>1.116323</td>\n",
       "      <td>4.108943</td>\n",
       "      <td>15.869687</td>\n",
       "      <td>4.110795</td>\n",
       "      <td>1.154079</td>\n",
       "      <td>2.159015</td>\n",
       "      <td>5.714450</td>\n",
       "      <td>0.442177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.317500e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.442869e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.970043e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.394551e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999264e+08</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      KIDSDRIV           AGE      HOMEKIDS          YOJ  \\\n",
       "count  1.030200e+04  10302.000000  10295.000000  10302.000000  9754.000000   \n",
       "mean   4.956631e+08      0.169288     44.837397      0.720443    10.474062   \n",
       "std    2.864675e+08      0.506512      8.606445      1.116323     4.108943   \n",
       "min    6.317500e+04      0.000000     16.000000      0.000000     0.000000   \n",
       "25%    2.442869e+08      0.000000     39.000000      0.000000     9.000000   \n",
       "50%    4.970043e+08      0.000000     45.000000      0.000000    11.000000   \n",
       "75%    7.394551e+08      0.000000     51.000000      1.000000    13.000000   \n",
       "max    9.999264e+08      4.000000     81.000000      5.000000    23.000000   \n",
       "\n",
       "           TRAVTIME           TIF      CLM_FREQ       MVR_PTS      CAR_AGE  \\\n",
       "count  10302.000000  10302.000000  10302.000000  10302.000000  9663.000000   \n",
       "mean      33.416424      5.329159      0.800718      1.710153     8.298148   \n",
       "std       15.869687      4.110795      1.154079      2.159015     5.714450   \n",
       "min        5.000000      1.000000      0.000000      0.000000    -3.000000   \n",
       "25%       22.000000      1.000000      0.000000      0.000000     1.000000   \n",
       "50%       33.000000      4.000000      0.000000      1.000000     8.000000   \n",
       "75%       44.000000      7.000000      2.000000      3.000000    12.000000   \n",
       "max      142.000000     25.000000      5.000000     13.000000    28.000000   \n",
       "\n",
       "         CLAIM_FLAG  \n",
       "count  10302.000000  \n",
       "mean       0.266550  \n",
       "std        0.442177  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>BIRTH</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>CAR_USE</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CLM_AMT</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>CLAIM_FLAG</th>\n",
       "      <th>URBANICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63581743</td>\n",
       "      <td>0</td>\n",
       "      <td>16MAR39</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>$67,349</td>\n",
       "      <td>No</td>\n",
       "      <td>$0</td>\n",
       "      <td>z_No</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Professional</td>\n",
       "      <td>14</td>\n",
       "      <td>Private</td>\n",
       "      <td>$14,230</td>\n",
       "      <td>11</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>$4,461</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>$0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132761049</td>\n",
       "      <td>0</td>\n",
       "      <td>21JAN56</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>$91,449</td>\n",
       "      <td>No</td>\n",
       "      <td>$257,252</td>\n",
       "      <td>z_No</td>\n",
       "      <td>M</td>\n",
       "      <td>z_High School</td>\n",
       "      <td>z_Blue Collar</td>\n",
       "      <td>22</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>$14,940</td>\n",
       "      <td>1</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>$0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>$0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  KIDSDRIV    BIRTH   AGE  HOMEKIDS   YOJ   INCOME PARENT1  \\\n",
       "0   63581743         0  16MAR39  60.0         0  11.0  $67,349      No   \n",
       "1  132761049         0  21JAN56  43.0         0  11.0  $91,449      No   \n",
       "\n",
       "   HOME_VAL MSTATUS GENDER      EDUCATION     OCCUPATION  TRAVTIME  \\\n",
       "0        $0    z_No      M            PhD   Professional        14   \n",
       "1  $257,252    z_No      M  z_High School  z_Blue Collar        22   \n",
       "\n",
       "      CAR_USE BLUEBOOK  TIF CAR_TYPE RED_CAR OLDCLAIM  CLM_FREQ REVOKED  \\\n",
       "0     Private  $14,230   11  Minivan     yes   $4,461         2      No   \n",
       "1  Commercial  $14,940    1  Minivan     yes       $0         0      No   \n",
       "\n",
       "   MVR_PTS CLM_AMT  CAR_AGE  CLAIM_FLAG           URBANICITY  \n",
       "0        3      $0     18.0           0  Highly Urban/ Urban  \n",
       "1        0      $0      1.0           0  Highly Urban/ Urban  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7556\n"
     ]
    }
   ],
   "source": [
    "a = sum(df['CLAIM_FLAG'] == False)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2746\n"
     ]
    }
   ],
   "source": [
    "b = sum(df['CLAIM_FLAG'] == True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   KIDSDRIV   AGE  HOMEKIDS   YOJ   INCOME PARENT1  HOME_VAL MSTATUS GENDER  \\\n",
      "0         0  60.0         0  11.0  $67,349      No        $0      No      M   \n",
      "1         0  43.0         0  11.0  $91,449      No  $257,252      No      M   \n",
      "2         0  48.0         0  11.0  $52,881      No        $0      No      M   \n",
      "3         0  35.0         1  10.0  $16,039      No  $124,191     Yes      F   \n",
      "4         0  51.0         0  14.0      NaN      No  $306,251     Yes      M   \n",
      "\n",
      "      EDUCATION    OCCUPATION  TRAVTIME     CAR_USE BLUEBOOK  TIF CAR_TYPE  \\\n",
      "0           PhD  Professional        14     Private  $14,230   11  Minivan   \n",
      "1   High School   Blue Collar        22  Commercial  $14,940    1  Minivan   \n",
      "2     Bachelors       Manager        26     Private  $21,970    1      Van   \n",
      "3   High School      Clerical         5     Private   $4,010    4      SUV   \n",
      "4  <High School   Blue Collar        32     Private  $15,440    7  Minivan   \n",
      "\n",
      "  RED_CAR OLDCLAIM  CLM_FREQ REVOKED  MVR_PTS CLM_AMT  CAR_AGE  CLAIM_FLAG  \\\n",
      "0     yes   $4,461         2      No        3      $0     18.0           0   \n",
      "1     yes       $0         0      No        0      $0      1.0           0   \n",
      "2     yes       $0         0      No        2      $0     10.0           0   \n",
      "3      no  $38,690         2      No        3      $0     10.0           0   \n",
      "4     yes       $0         0      No        0      $0      6.0           0   \n",
      "\n",
      "            URBANICITY  \n",
      "0  Highly Urban/ Urban  \n",
      "1  Highly Urban/ Urban  \n",
      "2  Highly Urban/ Urban  \n",
      "3  Highly Urban/ Urban  \n",
      "4  Highly Urban/ Urban  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['ID','BIRTH'],axis=1)\n",
    "df = df.applymap(lambda x: x.replace('z_', '') if isinstance(x, str) else x)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['KIDSDRIV', 'AGE', 'HOMEKIDS', 'YOJ', 'INCOME', 'HOME_VAL', 'TRAVTIME', 'BLUEBOOK', 'TIF', 'OLDCLAIM', 'CLM_FREQ', 'MVR_PTS', 'CAR_AGE']\n",
      "Categorical columns: ['PARENT1', 'MSTATUS', 'GENDER', 'EDUCATION', 'OCCUPATION', 'CAR_USE', 'CAR_TYPE', 'RED_CAR', 'REVOKED', 'URBANICITY']\n"
     ]
    }
   ],
   "source": [
    "numerical = [\n",
    "    'KIDSDRIV', 'AGE', 'HOMEKIDS', 'YOJ', 'INCOME',\n",
    "    'HOME_VAL', 'TRAVTIME', 'BLUEBOOK', 'TIF', 'OLDCLAIM',\n",
    "    'CLM_FREQ', 'MVR_PTS',  'CAR_AGE'\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "  'PARENT1', 'MSTATUS', 'GENDER', 'EDUCATION',\n",
    "    'OCCUPATION', 'CAR_USE', 'CAR_TYPE', 'RED_CAR', 'REVOKED', 'URBANICITY'\n",
    "]\n",
    "\n",
    "df[categorical] = df[categorical].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "        \n",
    "def clean_currency(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.replace('$','').replace(',',''))\n",
    "    return x\n",
    "\n",
    "for col in ['INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM', 'CLM_AMT']:\n",
    "    df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "\n",
    "print(\"Numerical columns:\", numerical)\n",
    "print(\"Categorical columns:\", categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical),\n",
    "        (\"cat\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder())\n",
    "        ]), categorical)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ROC-AUC: 0.8114692760775519 ± 0.016840503120660884\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['CLAIM_FLAG', 'CLM_AMT'], axis=1)\n",
    "y = df['CLAIM_FLAG']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "print(f'Cross-validation ROC-AUC: {scores.mean()} ± {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['KIDSDRIV', 'AGE', 'HOMEKIDS', 'YOJ', 'INCOME', 'PARENT1', 'HOME_VAL',\n",
      "       'MSTATUS', 'GENDER', 'EDUCATION', 'OCCUPATION', 'TRAVTIME', 'CAR_USE',\n",
      "       'BLUEBOOK', 'TIF', 'CAR_TYPE', 'RED_CAR', 'OLDCLAIM', 'CLM_FREQ',\n",
      "       'REVOKED', 'MVR_PTS', 'CLM_AMT', 'CAR_AGE', 'CLAIM_FLAG', 'URBANICITY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get feature importances (absolute coefficients for logistic regression)\n",
    "# importances = np.abs(pipeline..coef_[0])\n",
    "# feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "# feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1512\n",
      "           1       0.69      0.44      0.54       549\n",
      "\n",
      "    accuracy                           0.80      2061\n",
      "   macro avg       0.76      0.69      0.71      2061\n",
      "weighted avg       0.79      0.80      0.78      2061\n",
      "\n",
      "ROC-AUC Score: 0.8123235126878114\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['GENDER', 'EDUCATION', 'MSTATUS', 'PARENT1', 'OCCUPATION', 'URBANICITY']\n",
    "results = []\n",
    "privileged = {}\n",
    "for group in groups:\n",
    "    privileged[group] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Group': 'GENDER', 'Value': 'M', 'Accuracy': 0.8117770767613038, 'ROC-AUC': 0.8168753557199773, 'TP': 113, 'TN': 659, 'FP': 41, 'FN': 138}\n",
      "{'Group': 'GENDER', 'Value': 'F', 'Accuracy': 0.7882882882882883, 'ROC-AUC': 0.8078115184977022, 'TP': 129, 'TN': 746, 'FP': 66, 'FN': 169}\n",
      "{'Group': 'EDUCATION', 'Value': 'High School', 'Accuracy': 0.7670068027210885, 'ROC-AUC': 0.8293456071614236, 'TP': 114, 'TN': 337, 'FP': 44, 'FN': 93}\n",
      "{'Group': 'EDUCATION', 'Value': 'Bachelors', 'Accuracy': 0.8271375464684015, 'ROC-AUC': 0.8290478416705626, 'TP': 53, 'TN': 392, 'FP': 22, 'FN': 71}\n",
      "{'Group': 'EDUCATION', 'Value': 'Masters', 'Accuracy': 0.8259860788863109, 'ROC-AUC': 0.7397823869432166, 'TP': 16, 'TN': 340, 'FP': 6, 'FN': 69}\n",
      "{'Group': 'EDUCATION', 'Value': '<High School', 'Accuracy': 0.752442996742671, 'ROC-AUC': 0.7963286713286714, 'TP': 52, 'TN': 179, 'FP': 29, 'FN': 47}\n",
      "{'Group': 'EDUCATION', 'Value': 'PhD', 'Accuracy': 0.8324873096446701, 'ROC-AUC': 0.7244677011909058, 'TP': 7, 'TN': 157, 'FP': 6, 'FN': 27}\n",
      "{'Group': 'MSTATUS', 'Value': 'No', 'Accuracy': 0.7667887667887668, 'ROC-AUC': 0.7876787826648026, 'TP': 148, 'TN': 480, 'FP': 67, 'FN': 124}\n",
      "{'Group': 'MSTATUS', 'Value': 'Yes', 'Accuracy': 0.820450885668277, 'ROC-AUC': 0.8233590841922148, 'TP': 94, 'TN': 925, 'FP': 40, 'FN': 183}\n",
      "{'Group': 'PARENT1', 'Value': 'No', 'Accuracy': 0.806577480490524, 'ROC-AUC': 0.8073207558732358, 'TP': 160, 'TN': 1287, 'FP': 76, 'FN': 271}\n",
      "{'Group': 'PARENT1', 'Value': 'Yes', 'Accuracy': 0.7490636704119851, 'ROC-AUC': 0.7913206688658856, 'TP': 82, 'TN': 118, 'FP': 31, 'FN': 36}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Blue Collar', 'Accuracy': 0.7396351575456053, 'ROC-AUC': 0.7853684184783938, 'TP': 106, 'TN': 340, 'FP': 57, 'FN': 100}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Home Maker', 'Accuracy': 0.8068181818181818, 'ROC-AUC': 0.8304063360881543, 'TP': 18, 'TN': 124, 'FP': 8, 'FN': 26}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Professional', 'Accuracy': 0.8211678832116789, 'ROC-AUC': 0.8070872274143303, 'TP': 20, 'TN': 205, 'FP': 9, 'FN': 40}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Manager', 'Accuracy': 0.8602941176470589, 'ROC-AUC': 0.6767881241565452, 'TP': 0, 'TN': 234, 'FP': 0, 'FN': 38}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Clerical', 'Accuracy': 0.8107255520504731, 'ROC-AUC': 0.8729697849559932, 'TP': 62, 'TN': 195, 'FP': 19, 'FN': 41}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Student', 'Accuracy': 0.75625, 'ROC-AUC': 0.7792539601430761, 'TP': 29, 'TN': 92, 'FP': 11, 'FN': 28}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Lawyer', 'Accuracy': 0.8585858585858586, 'ROC-AUC': 0.7591269841269841, 'TP': 5, 'TN': 165, 'FP': 3, 'FN': 25}\n",
      "{'Group': 'OCCUPATION', 'Value': 'Doctor', 'Accuracy': 0.8524590163934426, 'ROC-AUC': 0.750909090909091, 'TP': 2, 'TN': 50, 'FP': 0, 'FN': 9}\n",
      "{'Group': 'URBANICITY', 'Value': 'Highly Urban/ Urban', 'Accuracy': 0.7661241711874623, 'ROC-AUC': 0.7896682196429052, 'TP': 242, 'TN': 1029, 'FP': 107, 'FN': 281}\n",
      "{'Group': 'URBANICITY', 'Value': 'Highly Rural/ Rural', 'Accuracy': 0.9353233830845771, 'ROC-AUC': 0.730973813420622, 'TP': 0, 'TN': 376, 'FP': 0, 'FN': 26}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(X_test, y_test, y_pred, y_pred_proba, group):\n",
    "    results = []\n",
    "    for value in X_test[group].unique():\n",
    "        mask = X_test[group] == value\n",
    "        if mask.sum() > 0:\n",
    "            group_y_test = y_test[mask]\n",
    "            group_y_pred = y_pred[mask]\n",
    "            group_y_pred_proba = y_pred_proba[mask]\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(group_y_test, group_y_pred_proba)\n",
    "            except ValueError:\n",
    "                roc_auc = float('nan')\n",
    "            tn, fp, fn, tp = confusion_matrix(group_y_test, group_y_pred).ravel()\n",
    "\n",
    "            results.append({\n",
    "                \"Group\": group,\n",
    "                \"Value\": value,\n",
    "                \"Accuracy\": (group_y_test == group_y_pred).mean(),\n",
    "                \"ROC-AUC\": roc_auc,\n",
    "                \"TP\": tp,\n",
    "                \"TN\": tn,\n",
    "                \"FP\": fp,\n",
    "                \"FN\": fn\n",
    "            })\n",
    "\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "    \n",
    "for group in groups:\n",
    "    results = evaluate_accuracy(X_test, y_test, y_pred, y_pred_proba, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each group, we calculate its fairness, based on its equalized odds difference, demographic parity difference, demographic parity ratio.\n",
    "\n",
    "Then, for each group we calculate the privileged and the unprivileged classes, based on the distance each class' value has with the most favoured value in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fairness(y_true, y_pred, sensitive_features, group_name):\n",
    "    eod = equalized_odds_difference(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        sensitive_features=sensitive_features\n",
    "    )\n",
    "    \n",
    "    dpd = demographic_parity_difference(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=sensitive_features\n",
    "    )\n",
    "    \n",
    "    di_ratio = demographic_parity_ratio(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=sensitive_features\n",
    "    )\n",
    "    \n",
    "    print(f'\\n group is {group_name}')\n",
    "    print(f\"Demographic Parity Ratio: {di_ratio:.4f}\")\n",
    "    print(f\"Equalized Odds Difference: {eod:.4f}\")\n",
    "    print(f\"Demographic Parity Difference: {dpd:.4f}\")\n",
    "    \n",
    "    \n",
    "    positive_rates = {}\n",
    "    for group_value in sensitive_features.unique():\n",
    "        mask = sensitive_features == group_value\n",
    "        group_y_pred = y_pred[mask]\n",
    "        positive_rate = group_y_pred.mean()\n",
    "        positive_rates[group_value] = positive_rate\n",
    "        print(f\"Subgroup: {group_value}, Positive Prediction Rate: {positive_rate:.4f}\")\n",
    "    \n",
    "    max_rate = max(positive_rates.values())\n",
    "    min_rate = min(positive_rates.values())\n",
    "    \n",
    "    positive_rates = dict(sorted(positive_rates.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    \n",
    "    values = list(positive_rates.values())\n",
    "    q1, q3 = np.percentile(values, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    threshold = iqr * 0.5 \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    for group_value, rate in positive_rates.items():\n",
    "        \n",
    "        if rate == min_rate or (rate - min_rate <= threshold):\n",
    "            print(f\"--> Privileged Group: {group_value} (Positive Rate: {rate:.4f})\")\n",
    "            \n",
    "            if 'privileged' in privileged[group_name]:\n",
    "                privileged[group_name]['privileged'].append(group_value)\n",
    "            else:\n",
    "                privileged[group_name]['privileged'] = [group_value]\n",
    "\n",
    "        elif rate == max_rate:\n",
    "            \n",
    "            print(f\"--> Unprivileged Group: {group_value} (Positive Rate: {rate:.4f})\")\n",
    "            if 'unprivileged' in privileged[group_name]:\n",
    "                privileged[group_name]['unprivileged'].append(group_value)\n",
    "            else:\n",
    "                privileged[group_name]['unprivileged'] = [group_value]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " group is EDUCATION\n",
      "Demographic Parity Ratio: 0.1900\n",
      "Equalized Odds Difference: 0.3625\n",
      "Demographic Parity Difference: 0.2177\n",
      "Subgroup: High School, Positive Prediction Rate: 0.2687\n",
      "Subgroup: Bachelors, Positive Prediction Rate: 0.1394\n",
      "Subgroup: Masters, Positive Prediction Rate: 0.0510\n",
      "Subgroup: <High School, Positive Prediction Rate: 0.2638\n",
      "Subgroup: PhD, Positive Prediction Rate: 0.0660\n",
      "--> Privileged Group: Masters (Positive Rate: 0.0510)\n",
      "--> Privileged Group: PhD (Positive Rate: 0.0660)\n",
      "--> Privileged Group: Bachelors (Positive Rate: 0.1394)\n",
      "--> Unprivileged Group: High School (Positive Rate: 0.2687)\n",
      "\n",
      " group is MSTATUS\n",
      "Demographic Parity Ratio: 0.4110\n",
      "Equalized Odds Difference: 0.2048\n",
      "Demographic Parity Difference: 0.1546\n",
      "Subgroup: No, Positive Prediction Rate: 0.2625\n",
      "Subgroup: Yes, Positive Prediction Rate: 0.1079\n",
      "--> Privileged Group: Yes (Positive Rate: 0.1079)\n",
      "--> Unprivileged Group: No (Positive Rate: 0.2625)\n",
      "\n",
      " group is PARENT1\n",
      "Demographic Parity Ratio: 0.3108\n",
      "Equalized Odds Difference: 0.3237\n",
      "Demographic Parity Difference: 0.2917\n",
      "Subgroup: No, Positive Prediction Rate: 0.1315\n",
      "Subgroup: Yes, Positive Prediction Rate: 0.4232\n",
      "--> Privileged Group: No (Positive Rate: 0.1315)\n",
      "--> Unprivileged Group: Yes (Positive Rate: 0.4232)\n",
      "\n",
      " group is OCCUPATION\n",
      "Demographic Parity Ratio: 0.0000\n",
      "Equalized Odds Difference: 0.6019\n",
      "Demographic Parity Difference: 0.2703\n",
      "Subgroup: Blue Collar, Positive Prediction Rate: 0.2703\n",
      "Subgroup: Home Maker, Positive Prediction Rate: 0.1477\n",
      "Subgroup: Professional, Positive Prediction Rate: 0.1058\n",
      "Subgroup: Manager, Positive Prediction Rate: 0.0000\n",
      "Subgroup: Clerical, Positive Prediction Rate: 0.2555\n",
      "Subgroup: Student, Positive Prediction Rate: 0.2500\n",
      "Subgroup: Lawyer, Positive Prediction Rate: 0.0404\n",
      "Subgroup: Doctor, Positive Prediction Rate: 0.0328\n",
      "--> Privileged Group: Manager (Positive Rate: 0.0000)\n",
      "--> Privileged Group: Doctor (Positive Rate: 0.0328)\n",
      "--> Privileged Group: Lawyer (Positive Rate: 0.0404)\n",
      "--> Privileged Group: Professional (Positive Rate: 0.1058)\n",
      "--> Unprivileged Group: Blue Collar (Positive Rate: 0.2703)\n",
      "\n",
      " group is URBANICITY\n",
      "Demographic Parity Ratio: 0.0000\n",
      "Equalized Odds Difference: 0.4627\n",
      "Demographic Parity Difference: 0.2104\n",
      "Subgroup: Highly Urban/ Urban, Positive Prediction Rate: 0.2104\n",
      "Subgroup: Highly Rural/ Rural, Positive Prediction Rate: 0.0000\n",
      "--> Privileged Group: Highly Rural/ Rural (Positive Rate: 0.0000)\n",
      "--> Unprivileged Group: Highly Urban/ Urban (Positive Rate: 0.2104)\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    if group not in ['GENDER','URBANINCITY']:\n",
    "        evaluate_fairness(y_test, y_pred, X_test[group], group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above fairness metrics, we will remove gender and marital status from our groups list, for we do not deem them biased enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>CAR_USE</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CLM_AMT</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>CLAIM_FLAG</th>\n",
       "      <th>URBANICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67349.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Professional</td>\n",
       "      <td>14</td>\n",
       "      <td>Private</td>\n",
       "      <td>14230.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>91449.0</td>\n",
       "      <td>No</td>\n",
       "      <td>257252.0</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>High School</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>22</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>14940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KIDSDRIV   AGE  HOMEKIDS   YOJ   INCOME PARENT1  HOME_VAL MSTATUS GENDER  \\\n",
       "0         0  60.0         0  11.0  67349.0      No       0.0      No      M   \n",
       "1         0  43.0         0  11.0  91449.0      No  257252.0      No      M   \n",
       "\n",
       "     EDUCATION    OCCUPATION  TRAVTIME     CAR_USE  BLUEBOOK  TIF CAR_TYPE  \\\n",
       "0          PhD  Professional        14     Private   14230.0   11  Minivan   \n",
       "1  High School   Blue Collar        22  Commercial   14940.0    1  Minivan   \n",
       "\n",
       "  RED_CAR  OLDCLAIM  CLM_FREQ REVOKED  MVR_PTS  CLM_AMT  CAR_AGE  CLAIM_FLAG  \\\n",
       "0     yes    4461.0         2      No        3      0.0     18.0           0   \n",
       "1     yes       0.0         0      No        0      0.0      1.0           0   \n",
       "\n",
       "            URBANICITY  \n",
       "0  Highly Urban/ Urban  \n",
       "1  Highly Urban/ Urban  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the columns occupation, parent1, and occupation indicate the presence of bias in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GENDER', 'EDUCATION', 'MSTATUS', 'PARENT1', 'OCCUPATION', 'URBANICITY']\n"
     ]
    }
   ],
   "source": [
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.remove('MSTATUS')\n",
    "groups.remove('GENDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION {'privileged': ['Masters', 'PhD', 'Bachelors'], 'unprivileged': ['High School']}\n",
      "PARENT1 {'privileged': ['No'], 'unprivileged': ['Yes']}\n",
      "OCCUPATION {'privileged': ['Manager', 'Doctor', 'Lawyer', 'Professional'], 'unprivileged': ['Blue Collar']}\n",
      "URBANICITY {'privileged': ['Highly Rural/ Rural'], 'unprivileged': ['Highly Urban/ Urban']}\n"
     ]
    }
   ],
   "source": [
    "del privileged['GENDER']\n",
    "del privileged['MSTATUS']\n",
    "for keys,values in privileged.items():\n",
    "    print(keys,values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use aif360 for mitigating bias in the education column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privileged classes for group EDUCATION are ['Masters', 'PhD', 'Bachelors']\n",
      "unprivileged classes for group EDUCATION are ['High School']\n",
      "privileged classes for group PARENT1 are ['No']\n",
      "unprivileged classes for group PARENT1 are ['Yes']\n",
      "privileged classes for group OCCUPATION are ['Manager', 'Doctor', 'Lawyer', 'Professional']\n",
      "unprivileged classes for group OCCUPATION are ['Blue Collar']\n",
      "privileged classes for group URBANICITY are ['Highly Rural/ Rural']\n",
      "unprivileged classes for group URBANICITY are ['Highly Urban/ Urban']\n",
      "Encoded MSTATUS: {'No': 0, 'Yes': 1}\n",
      "Encoded GENDER: {'F': 0, 'M': 1}\n",
      "Encoded CAR_USE: {'Commercial': 0, 'Private': 1}\n",
      "Encoded CAR_TYPE: {'Minivan': 0, 'Panel Truck': 1, 'Pickup': 2, 'SUV': 3, 'Sports Car': 4, 'Van': 5}\n",
      "Encoded RED_CAR: {'no': 0, 'yes': 1}\n",
      "Encoded REVOKED: {'No': 0, 'Yes': 1}\n",
      "Encoded EDUCATION: {'<High School': 0, 'Bachelors': 1, 'High School': 2, 'Masters': 3, 'PhD': 4}\n",
      "Encoded OCCUPATION: {'Blue Collar': 0, 'Clerical': 1, 'Doctor': 2, 'Home Maker': 3, 'Lawyer': 4, 'Manager': 5, 'Professional': 6, 'Student': 7}\n",
      "Encoded PARENT1: {'No': 0, 'Yes': 1}\n",
      "Encoded URBANICITY: {'Highly Rural/ Rural': 0, 'Highly Urban/ Urban': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for group in groups:\n",
    "    \n",
    "    aif_dict = {}\n",
    "\n",
    "    for element in privileged[group]['privileged']:    \n",
    "        aif_dict[element] = 1\n",
    "    \n",
    "    for element in privileged[group]['unprivileged']:\n",
    "        aif_dict[element] = 0\n",
    "\n",
    "\n",
    "    privileged_class = [key for key, value in aif_dict.items() if value == 1]\n",
    "    unprivileged_class = [key for key, value in aif_dict.items() if value == 0]\n",
    "\n",
    "    print(f'privileged classes for group {group} are {privileged_class}')\n",
    "    print(f'unprivileged classes for group {group} are {unprivileged_class}')\n",
    "    \n",
    "    #map column values to 0,1 s, based on whether or not the entry is privileged\n",
    "    #df[group] = df[group].apply(lambda x: 1 if x in(privileged_class) else 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "categorical_columns = [\n",
    "    'MSTATUS', 'GENDER', 'CAR_USE', 'CAR_TYPE', 'RED_CAR', 'REVOKED', 'EDUCATION', 'OCCUPATION','PARENT1','URBANICITY'\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Fit and transform the column to encode categorical values\n",
    "    df[col] = encoder.fit_transform(df[col].astype(str))  # Ensure all categories are considered by converting to string\n",
    "\n",
    "    # Optionally, print the mapping of original values to encoded labels\n",
    "    print(f\"Encoded {col}: {dict(zip(encoder.classes_, range(len(encoder.classes_))))}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collect all unique class values from all columns\n",
    "all_unique_values = set()\n",
    "\n",
    "# Collect unique values for each column\n",
    "for col in categorical_columns:\n",
    "    all_unique_values.update(df[col].astype(str).unique())\n",
    "\n",
    "encoder.fit(sorted(all_unique_values)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>CAR_USE</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CLM_AMT</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>CLAIM_FLAG</th>\n",
       "      <th>URBANICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67349.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14230.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>91449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>257252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>14940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KIDSDRIV   AGE  HOMEKIDS   YOJ   INCOME  PARENT1  HOME_VAL  MSTATUS  \\\n",
       "0         0  60.0         0  11.0  67349.0        0       0.0        0   \n",
       "1         0  43.0         0  11.0  91449.0        0  257252.0        0   \n",
       "\n",
       "   GENDER  EDUCATION  OCCUPATION  TRAVTIME  CAR_USE  BLUEBOOK  TIF  CAR_TYPE  \\\n",
       "0       1          4           6        14        1   14230.0   11         0   \n",
       "1       1          2           0        22        0   14940.0    1         0   \n",
       "\n",
       "   RED_CAR  OLDCLAIM  CLM_FREQ  REVOKED  MVR_PTS  CLM_AMT  CAR_AGE  \\\n",
       "0        1    4461.0         2        0        3      0.0     18.0   \n",
       "1        1       0.0         0        0        0      0.0      1.0   \n",
       "\n",
       "   CLAIM_FLAG  URBANICITY  \n",
       "0           0           1  \n",
       "1           0           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoded_df = encode_df(df)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "22  URBANICITY    2.176261\n",
      "19     REVOKED    0.807494\n",
      "12     CAR_USE    0.743553\n",
      "7      MSTATUS    0.352968\n",
      "5      PARENT1    0.323293\n",
      "4       INCOME    0.240328\n",
      "14         TIF    0.233565\n",
      "6     HOME_VAL    0.227768\n",
      "20     MVR_PTS    0.224410\n",
      "0     KIDSDRIV    0.218072\n",
      "11    TRAVTIME    0.213465\n",
      "18    CLM_FREQ    0.200429\n",
      "15    CAR_TYPE    0.138125\n",
      "13    BLUEBOOK    0.136032\n",
      "21     CAR_AGE    0.112820\n",
      "17    OLDCLAIM    0.081530\n",
      "2     HOMEKIDS    0.079110\n",
      "8       GENDER    0.058362\n",
      "10  OCCUPATION    0.056933\n",
      "3          YOJ    0.051669\n",
      "16     RED_CAR    0.030251\n",
      "1          AGE    0.028408\n",
      "9    EDUCATION    0.018256\n"
     ]
    }
   ],
   "source": [
    "importances = np.abs(model.coef_[0])\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object': \n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIF 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an AIF360 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_name = 'CLAIM_FLAG'\n",
    "favorable_classes = [0]\n",
    "protected_attribute_names = ['EDUCATION', 'PARENT1', 'OCCUPATION']\n",
    "privileged_classes = [[4,3], [0], [5,4,2]]  \n",
    "\n",
    "# Optional parameters (if needed)\n",
    "#categorical_features = ['MSTATUS', 'GENDER', 'CAR_USE', 'CAR_TYPE', 'RED_CAR', 'REVOKED']  # Specify categorical features\n",
    "features_to_drop = ['id', 'address', 'CLM_AMT']  # Columns to drop (if any)\n",
    "na_values = ['NA', '?', '']  # Handle missing values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[numerical] = df[numerical].fillna(df[numerical].mean())\n",
    "df[categorical] = df[categorical].fillna(df[categorical].mode().iloc[0])\n",
    "scaler = StandardScaler()\n",
    "df[numerical] = scaler.fit_transform(df[numerical])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = StandardDataset(\n",
    "    df.drop('CLM_AMT',axis=1),\n",
    "    label_name=label_name,\n",
    "    favorable_classes=favorable_classes,\n",
    "    protected_attribute_names=protected_attribute_names,\n",
    "    privileged_classes=privileged_classes,\n",
    "    # categorical_features=categorical_columns,  # Pass all categorical columns\n",
    "    # features_to_drop=features_to_drop,\n",
    "    # na_values=na_values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define privileged and unprivileged groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprivileged_groups = [{'EDUCATION': 2}]\n",
    "privileged_groups = [{'EDUCATION': 4}, {'EDUCATION': 3}, {'EDUCATION': 1}] \n",
    "\n",
    "unprivileged_groups.append({'PARENT1': 1})\n",
    "privileged_groups.append({'PARENT1': 0})\n",
    "\n",
    "unprivileged_groups.append({'OCCUPATION': 7})\n",
    "privileged_groups.append({'OCCUPATION': 5})\n",
    "privileged_groups.append({'OCCUPATION' : 4}) \n",
    "privileged_groups.append({'OCCUPATION' : 2}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing mitigation techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\steve\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reweighing = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "\n",
    "reweighed_data = reweighing.fit_transform(dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reweighed_data.features, reweighed_data.labels.ravel(), test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=0.1, random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "dataset_test = dataset.copy()\n",
    "dataset_test.features = X_test\n",
    "dataset_test.labels = y_test\n",
    "\n",
    "reweighed_dataset_test = dataset.copy()\n",
    "reweighed_dataset_test.features = X_test\n",
    "reweighed_dataset_test.labels = y_pred\n",
    "\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Group': 'EDUCATION', 'Value': 2.0, 'Accuracy': 0.7338618346545867, 'ROC-AUC': 0.8087274061228572, 'TP': 150, 'TN': 498, 'FP': 66, 'FN': 169}\n",
      "{'Group': 'EDUCATION', 'Value': 3.0, 'Accuracy': 0.8508634222919937, 'ROC-AUC': 0.790770401747303, 'TP': 32, 'TN': 510, 'FP': 11, 'FN': 84}\n",
      "{'Group': 'EDUCATION', 'Value': 1.0, 'Accuracy': 0.8192352259559675, 'ROC-AUC': 0.7874825269423277, 'TP': 74, 'TN': 633, 'FP': 29, 'FN': 127}\n",
      "{'Group': 'EDUCATION', 'Value': 4.0, 'Accuracy': 0.8689138576779026, 'ROC-AUC': 0.7849125836391108, 'TP': 10, 'TN': 222, 'FP': 4, 'FN': 31}\n",
      "{'Group': 'EDUCATION', 'Value': 0.0, 'Accuracy': 0.7596371882086168, 'ROC-AUC': 0.7976781982818668, 'TP': 71, 'TN': 264, 'FP': 31, 'FN': 75}\n",
      "{'Group': 'PARENT1', 'Value': 0.0, 'Accuracy': 0.7990377498149519, 'ROC-AUC': 0.7991477014733597, 'TP': 216, 'TN': 1943, 'FP': 110, 'FN': 433}\n",
      "{'Group': 'PARENT1', 'Value': 1.0, 'Accuracy': 0.7840616966580977, 'ROC-AUC': 0.822106388666132, 'TP': 121, 'TN': 184, 'FP': 31, 'FN': 53}\n",
      "{'Group': 'OCCUPATION', 'Value': 6.0, 'Accuracy': 0.7934272300469484, 'ROC-AUC': 0.7687868045586381, 'TP': 21, 'TN': 317, 'FP': 2, 'FN': 86}\n",
      "{'Group': 'OCCUPATION', 'Value': 3.0, 'Accuracy': 0.833976833976834, 'ROC-AUC': 0.8390804597701149, 'TP': 28, 'TN': 188, 'FP': 13, 'FN': 30}\n",
      "{'Group': 'OCCUPATION', 'Value': 0.0, 'Accuracy': 0.7398843930635838, 'ROC-AUC': 0.8111344613935287, 'TP': 133, 'TN': 507, 'FP': 72, 'FN': 153}\n",
      "{'Group': 'OCCUPATION', 'Value': 5.0, 'Accuracy': 0.8733153638814016, 'ROC-AUC': 0.7382610939112486, 'TP': 12, 'TN': 312, 'FP': 11, 'FN': 36}\n",
      "{'Group': 'OCCUPATION', 'Value': 4.0, 'Accuracy': 0.8682634730538922, 'ROC-AUC': 0.7242724867724868, 'TP': 11, 'TN': 279, 'FP': 1, 'FN': 43}\n",
      "{'Group': 'OCCUPATION', 'Value': 1.0, 'Accuracy': 0.7679671457905544, 'ROC-AUC': 0.8073649436455499, 'TP': 71, 'TN': 303, 'FP': 29, 'FN': 84}\n",
      "{'Group': 'OCCUPATION', 'Value': 7.0, 'Accuracy': 0.7689393939393939, 'ROC-AUC': 0.8278727445394112, 'TP': 59, 'TN': 144, 'FP': 12, 'FN': 49}\n",
      "{'Group': 'OCCUPATION', 'Value': 2.0, 'Accuracy': 0.9294117647058824, 'ROC-AUC': 0.7673992673992674, 'TP': 2, 'TN': 77, 'FP': 1, 'FN': 5}\n"
     ]
    }
   ],
   "source": [
    "groups.remove('URBANICITY')\n",
    "\n",
    "for group in groups:\n",
    "    #evaluate_fairness(y_test, y_pred, X_test[group], group)\n",
    "    evaluate_accuracy(X_test, y_test, y_pred, y_pred_proba, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about resampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7269492073762537\n",
      "\n",
      " group is EDUCATION\n",
      "Demographic Parity Ratio: 0.3627\n",
      "Equalized Odds Difference: 0.3035\n",
      "Demographic Parity Difference: 0.3685\n",
      "Subgroup: 2, Positive Prediction Rate: 0.5504\n",
      "Subgroup: 3, Positive Prediction Rate: 0.2747\n",
      "Subgroup: 1, Positive Prediction Rate: 0.3673\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2097\n",
      "Subgroup: 0, Positive Prediction Rate: 0.5782\n",
      "--> Privileged Group: 4 (Positive Rate: 0.2097)\n",
      "--> Privileged Group: 3 (Positive Rate: 0.2747)\n",
      "--> Unprivileged Group: 0 (Positive Rate: 0.5782)\n",
      "\n",
      " group is PARENT1\n",
      "Demographic Parity Ratio: 0.6073\n",
      "Equalized Odds Difference: 0.1845\n",
      "Demographic Parity Difference: 0.2493\n",
      "Subgroup: 0, Positive Prediction Rate: 0.3856\n",
      "Subgroup: 1, Positive Prediction Rate: 0.6350\n",
      "--> Privileged Group: 0 (Positive Rate: 0.3856)\n",
      "--> Unprivileged Group: 1 (Positive Rate: 0.6350)\n",
      "\n",
      " group is OCCUPATION\n",
      "Demographic Parity Ratio: 0.1953\n",
      "Equalized Odds Difference: 0.5251\n",
      "Demographic Parity Difference: 0.4846\n",
      "Subgroup: 6, Positive Prediction Rate: 0.3709\n",
      "Subgroup: 3, Positive Prediction Rate: 0.4517\n",
      "Subgroup: 0, Positive Prediction Rate: 0.5364\n",
      "Subgroup: 5, Positive Prediction Rate: 0.1321\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2335\n",
      "Subgroup: 1, Positive Prediction Rate: 0.5216\n",
      "Subgroup: 7, Positive Prediction Rate: 0.6023\n",
      "Subgroup: 2, Positive Prediction Rate: 0.1176\n",
      "--> Privileged Group: 2 (Positive Rate: 0.1176)\n",
      "--> Privileged Group: 5 (Positive Rate: 0.1321)\n",
      "--> Privileged Group: 4 (Positive Rate: 0.2335)\n",
      "--> Unprivileged Group: 7 (Positive Rate: 0.6023)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical),\n",
    "        (\"cat\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder())\n",
    "        ]), categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"resampler\", smote),\n",
    "    (\"classifier\", LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "for group in groups:\n",
    "    evaluate_fairness(y_test,y_pred, X_test[group], group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In processing Mitigation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we ll try and test the results of adversial debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.823118; batch adversarial loss: 1.269651\n",
      "epoch 1; iter: 0; batch classifier loss: 0.655212; batch adversarial loss: 1.145022\n",
      "epoch 2; iter: 0; batch classifier loss: 0.667269; batch adversarial loss: 1.206553\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605778; batch adversarial loss: 1.013282\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645542; batch adversarial loss: 0.944553\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587292; batch adversarial loss: 0.771228\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595542; batch adversarial loss: 0.582338\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653243; batch adversarial loss: 0.408693\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583471; batch adversarial loss: 0.316789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546354; batch adversarial loss: 0.243634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466319; batch adversarial loss: 0.131687\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489528; batch adversarial loss: -0.036075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417642; batch adversarial loss: -0.347559\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417243; batch adversarial loss: -0.541277\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437244; batch adversarial loss: -0.688497\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: -0.752308\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439741; batch adversarial loss: -1.119436\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511740; batch adversarial loss: -1.531976\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414373; batch adversarial loss: -1.363703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445646; batch adversarial loss: -1.461938\n",
      "epoch 20; iter: 0; batch classifier loss: 0.399102; batch adversarial loss: -1.608447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429637; batch adversarial loss: -1.751773\n",
      "epoch 22; iter: 0; batch classifier loss: 0.352332; batch adversarial loss: -2.735721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468964; batch adversarial loss: -2.279767\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442697; batch adversarial loss: -2.228427\n",
      "epoch 25; iter: 0; batch classifier loss: 0.540935; batch adversarial loss: -2.737669\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400120; batch adversarial loss: -2.877659\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362907; batch adversarial loss: -2.467882\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419073; batch adversarial loss: -2.713614\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448379; batch adversarial loss: -3.192769\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499252; batch adversarial loss: -2.866293\n",
      "epoch 31; iter: 0; batch classifier loss: 0.371980; batch adversarial loss: -3.677206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490495; batch adversarial loss: -2.014757\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374247; batch adversarial loss: -3.440024\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406637; batch adversarial loss: -3.711227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407413; batch adversarial loss: -3.101180\n",
      "epoch 36; iter: 0; batch classifier loss: 0.350786; batch adversarial loss: -3.335487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392269; batch adversarial loss: -3.156505\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408139; batch adversarial loss: -3.910980\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370812; batch adversarial loss: -4.049975\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456913; batch adversarial loss: -4.365544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378462; batch adversarial loss: -3.286646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415316; batch adversarial loss: -3.993270\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459904; batch adversarial loss: -3.141448\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466640; batch adversarial loss: -4.486697\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471288; batch adversarial loss: -4.749883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430370; batch adversarial loss: -3.896930\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391467; batch adversarial loss: -4.735354\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367318; batch adversarial loss: -4.417809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514091; batch adversarial loss: -5.410816\n",
      "epoch 50; iter: 0; batch classifier loss: 0.335856; batch adversarial loss: -4.871764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470316; batch adversarial loss: -4.445758\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475850; batch adversarial loss: -4.795331\n",
      "epoch 53; iter: 0; batch classifier loss: 0.335268; batch adversarial loss: -4.422281\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438984; batch adversarial loss: -6.184086\n",
      "epoch 55; iter: 0; batch classifier loss: 0.430452; batch adversarial loss: -3.748811\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466815; batch adversarial loss: -6.220629\n",
      "epoch 57; iter: 0; batch classifier loss: 0.383198; batch adversarial loss: -5.517121\n",
      "epoch 58; iter: 0; batch classifier loss: 0.509747; batch adversarial loss: -5.327529\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400944; batch adversarial loss: -6.492881\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473698; batch adversarial loss: -6.008431\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407078; batch adversarial loss: -6.059759\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408090; batch adversarial loss: -6.130758\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424265; batch adversarial loss: -8.509027\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377855; batch adversarial loss: -7.184504\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372752; batch adversarial loss: -5.759678\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401995; batch adversarial loss: -5.637582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421592; batch adversarial loss: -6.810242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.460233; batch adversarial loss: -7.420341\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373990; batch adversarial loss: -6.168029\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421453; batch adversarial loss: -6.710455\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433287; batch adversarial loss: -7.636513\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414901; batch adversarial loss: -8.039232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435079; batch adversarial loss: -8.121864\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371431; batch adversarial loss: -8.725170\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423597; batch adversarial loss: -6.824378\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351259; batch adversarial loss: -7.935483\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421881; batch adversarial loss: -6.087846\n",
      "epoch 78; iter: 0; batch classifier loss: 0.419403; batch adversarial loss: -7.993464\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360598; batch adversarial loss: -7.089801\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420964; batch adversarial loss: -5.879001\n",
      "epoch 81; iter: 0; batch classifier loss: 0.350577; batch adversarial loss: -6.823012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.481261; batch adversarial loss: -7.085481\n",
      "epoch 83; iter: 0; batch classifier loss: 0.490304; batch adversarial loss: -7.426838\n",
      "epoch 84; iter: 0; batch classifier loss: 0.541242; batch adversarial loss: -8.370774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419908; batch adversarial loss: -7.601206\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415873; batch adversarial loss: -7.518133\n",
      "epoch 87; iter: 0; batch classifier loss: 0.511432; batch adversarial loss: -8.508944\n",
      "epoch 88; iter: 0; batch classifier loss: 0.469965; batch adversarial loss: -5.266335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447064; batch adversarial loss: -8.764868\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454921; batch adversarial loss: -9.720118\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402213; batch adversarial loss: -7.414761\n",
      "epoch 92; iter: 0; batch classifier loss: 0.531607; batch adversarial loss: -9.663202\n",
      "epoch 93; iter: 0; batch classifier loss: 0.302951; batch adversarial loss: -6.605789\n",
      "epoch 94; iter: 0; batch classifier loss: 0.517216; batch adversarial loss: -7.877354\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401854; batch adversarial loss: -9.940336\n",
      "epoch 96; iter: 0; batch classifier loss: 0.562593; batch adversarial loss: -8.275654\n",
      "epoch 97; iter: 0; batch classifier loss: 0.429427; batch adversarial loss: -8.586174\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450810; batch adversarial loss: -7.391822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381622; batch adversarial loss: -9.283653\n"
     ]
    }
   ],
   "source": [
    "unprivileged_groups = [{'EDUCATION': 2, 'PARENT1': 1, 'OCCUPATION': 7}]\n",
    "privileged_groups = [{'EDUCATION': 4, 'PARENT1': 0, 'OCCUPATION': 5}]\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "train_dataset, test_dataset = dataset.split([0.7], shuffle=True, seed=42)\n",
    "\n",
    "\n",
    "adversarial_model = AdversarialDebiasing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    scope_name='debiased_classifier',\n",
    "    sess=sess,\n",
    "    num_epochs=100,\n",
    "    batch_size=128,\n",
    "    classifier_num_hidden_units=100,\n",
    "    debias=True,\n",
    "    adversary_loss_weight=0.001\n",
    ")\n",
    "\n",
    "adversarial_model.fit(train_dataset)\n",
    "y_pred_adversarial = adversarial_model.predict(test_dataset).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Debiasing Results:\n",
      "Accuracy: 0.6285991588482692\n",
      "ROC-AUC: 0.5069271667084547\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.77      0.75      2268\n",
      "         1.0       0.28      0.25      0.26       823\n",
      "\n",
      "    accuracy                           0.63      3091\n",
      "   macro avg       0.51      0.51      0.51      3091\n",
      "weighted avg       0.61      0.63      0.62      3091\n",
      "\n",
      "\n",
      " group is EDUCATION\n",
      "Demographic Parity Ratio: 0.8114\n",
      "Equalized Odds Difference: 0.0606\n",
      "Demographic Parity Difference: 0.0488\n",
      "Subgroup: 2.0, Positive Prediction Rate: 0.2435\n",
      "Subgroup: 3.0, Positive Prediction Rate: 0.2386\n",
      "Subgroup: 1.0, Positive Prediction Rate: 0.2248\n",
      "Subgroup: 4.0, Positive Prediction Rate: 0.2097\n",
      "Subgroup: 0.0, Positive Prediction Rate: 0.2585\n",
      "--> Privileged Group: 4.0 (Positive Rate: 0.2097)\n",
      "--> Unprivileged Group: 0.0 (Positive Rate: 0.2585)\n",
      "\n",
      " group is PARENT1\n",
      "Demographic Parity Ratio: 0.9999\n",
      "Equalized Odds Difference: 0.0105\n",
      "Demographic Parity Difference: 0.0000\n",
      "Subgroup: 0.0, Positive Prediction Rate: 0.2365\n",
      "Subgroup: 1.0, Positive Prediction Rate: 0.2365\n",
      "--> Privileged Group: 0.0 (Positive Rate: 0.2365)\n",
      "--> Unprivileged Group: 1.0 (Positive Rate: 0.2365)\n",
      "\n",
      " group is OCCUPATION\n",
      "Demographic Parity Ratio: 0.7407\n",
      "Equalized Odds Difference: 0.1675\n",
      "Demographic Parity Difference: 0.0698\n",
      "Subgroup: 6.0, Positive Prediction Rate: 0.1995\n",
      "Subgroup: 3.0, Positive Prediction Rate: 0.2201\n",
      "Subgroup: 0.0, Positive Prediction Rate: 0.2694\n",
      "Subgroup: 5.0, Positive Prediction Rate: 0.2372\n",
      "Subgroup: 4.0, Positive Prediction Rate: 0.2275\n",
      "Subgroup: 1.0, Positive Prediction Rate: 0.2382\n",
      "Subgroup: 7.0, Positive Prediction Rate: 0.2045\n",
      "Subgroup: 2.0, Positive Prediction Rate: 0.2588\n",
      "--> Privileged Group: 6.0 (Positive Rate: 0.1995)\n",
      "--> Privileged Group: 7.0 (Positive Rate: 0.2045)\n",
      "--> Unprivileged Group: 0.0 (Positive Rate: 0.2694)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial Debiasing Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_adversarial))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_adversarial))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adversarial))\n",
    "for group in groups:\n",
    "    evaluate_fairness(y_test,y_pred_adversarial,X_test[group],group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairlearn Constrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will use it for a Demographic Parity Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6670980265286315\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical),\n",
    "        (\"cat\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder())\n",
    "        ]), categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "fair_model = ExponentiatedGradient(\n",
    "    estimator=lg, \n",
    "    constraints=DemographicParity(),\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"fair_classifier\", fair_model)\n",
    "])\n",
    "\n",
    "X = df.drop(columns=['CLM_AMT', 'CLAIM_FLAG'], axis=1)\n",
    "y = df['CLAIM_FLAG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "fair_model.fit(X_train, y_train, sensitive_features=X_train[groups])\n",
    "\n",
    "y_pred = fair_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " group is EDUCATION\n",
      "Demographic Parity Ratio: 0.6765\n",
      "Equalized Odds Difference: 0.0892\n",
      "Demographic Parity Difference: 0.0715\n",
      "Subgroup: 2, Positive Prediction Rate: 0.1959\n",
      "Subgroup: 3, Positive Prediction Rate: 0.1821\n",
      "Subgroup: 1, Positive Prediction Rate: 0.1495\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2210\n",
      "Subgroup: 0, Positive Prediction Rate: 0.2063\n",
      "--> Privileged Group: 1 (Positive Rate: 0.1495)\n",
      "--> Unprivileged Group: 4 (Positive Rate: 0.2210)\n",
      "\n",
      " group is PARENT1\n",
      "Demographic Parity Ratio: 0.8782\n",
      "Equalized Odds Difference: 0.0324\n",
      "Demographic Parity Difference: 0.0250\n",
      "Subgroup: 0, Positive Prediction Rate: 0.1806\n",
      "Subgroup: 1, Positive Prediction Rate: 0.2057\n",
      "--> Privileged Group: 0 (Positive Rate: 0.1806)\n",
      "--> Unprivileged Group: 1 (Positive Rate: 0.2057)\n",
      "\n",
      " group is OCCUPATION\n",
      "Demographic Parity Ratio: 0.7030\n",
      "Equalized Odds Difference: 0.2790\n",
      "Demographic Parity Difference: 0.0653\n",
      "Subgroup: 6, Positive Prediction Rate: 0.1573\n",
      "Subgroup: 3, Positive Prediction Rate: 0.1544\n",
      "Subgroup: 0, Positive Prediction Rate: 0.1827\n",
      "Subgroup: 5, Positive Prediction Rate: 0.1941\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2096\n",
      "Subgroup: 1, Positive Prediction Rate: 0.1786\n",
      "Subgroup: 7, Positive Prediction Rate: 0.2197\n",
      "Subgroup: 2, Positive Prediction Rate: 0.1882\n",
      "--> Privileged Group: 3 (Positive Rate: 0.1544)\n",
      "--> Privileged Group: 6 (Positive Rate: 0.1573)\n",
      "--> Unprivileged Group: 7 (Positive Rate: 0.2197)\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    evaluate_fairness(y_test, y_pred, X_test[group], group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate its results for choosing Equalized Odds as a fairness constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "c:\\Users\\steve\\Clio_Muse Data Analysis Project\\.conda\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6324813976059528\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical),\n",
    "        (\"cat\", Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder())\n",
    "        ]), categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "fair_model = ExponentiatedGradient(\n",
    "    estimator=log_reg, \n",
    "    constraints=EqualizedOdds(), \n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"fair_classifier\", fair_model)\n",
    "])\n",
    "\n",
    "X = df.drop(columns=['CLM_AMT', 'CLAIM_FLAG'], axis=1)\n",
    "y = df['CLAIM_FLAG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "fair_model.fit(X_train, y_train, sensitive_features=X_train[groups])\n",
    "\n",
    "y_pred = fair_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " group is EDUCATION\n",
      "Demographic Parity Ratio: 0.8702\n",
      "Equalized Odds Difference: 0.0929\n",
      "Demographic Parity Difference: 0.0313\n",
      "Subgroup: 2, Positive Prediction Rate: 0.2197\n",
      "Subgroup: 3, Positive Prediction Rate: 0.2245\n",
      "Subgroup: 1, Positive Prediction Rate: 0.2410\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2097\n",
      "Subgroup: 0, Positive Prediction Rate: 0.2404\n",
      "--> Privileged Group: 4 (Positive Rate: 0.2097)\n",
      "--> Privileged Group: 2 (Positive Rate: 0.2197)\n",
      "--> Unprivileged Group: 1 (Positive Rate: 0.2410)\n",
      "\n",
      " group is PARENT1\n",
      "Demographic Parity Ratio: 0.8863\n",
      "Equalized Odds Difference: 0.0326\n",
      "Demographic Parity Difference: 0.0264\n",
      "Subgroup: 0, Positive Prediction Rate: 0.2321\n",
      "Subgroup: 1, Positive Prediction Rate: 0.2057\n",
      "--> Privileged Group: 1 (Positive Rate: 0.2057)\n",
      "--> Unprivileged Group: 0 (Positive Rate: 0.2321)\n",
      "\n",
      " group is OCCUPATION\n",
      "Demographic Parity Ratio: 0.7345\n",
      "Equalized Odds Difference: 0.1645\n",
      "Demographic Parity Difference: 0.0684\n",
      "Subgroup: 6, Positive Prediction Rate: 0.2230\n",
      "Subgroup: 3, Positive Prediction Rate: 0.1892\n",
      "Subgroup: 0, Positive Prediction Rate: 0.2243\n",
      "Subgroup: 5, Positive Prediction Rate: 0.2372\n",
      "Subgroup: 4, Positive Prediction Rate: 0.2305\n",
      "Subgroup: 1, Positive Prediction Rate: 0.2444\n",
      "Subgroup: 7, Positive Prediction Rate: 0.2576\n",
      "Subgroup: 2, Positive Prediction Rate: 0.2000\n",
      "--> Privileged Group: 3 (Positive Rate: 0.1892)\n",
      "--> Privileged Group: 2 (Positive Rate: 0.2000)\n",
      "--> Unprivileged Group: 7 (Positive Rate: 0.2576)\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    evaluate_fairness(y_test, y_pred, X_test[group], group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
